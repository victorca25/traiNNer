name: VSR_x4
suffix: null
model: vsrgan # 
scale: 4
gpu_ids: [0]
chop_forward: false

datasets:
  test_1: # the 1st test dataset
    name: calendar
    mode: VLR
    #dataroot_HR: '../Vid4/calendar/HR'
    dataroot_LR: '../Vid4/calendar/LR'
    num_frames: 3 # the number of frames the network was trained to use to estimate the central frame
    srcolors: true # to generate images with 3 channels
    denoise_LRbic: true
    # tensor_shape: CTHW # TCHW (SOFVSR), CTHW (EVSRGAN)
  test_2: # the 2nd test dataset
    name: foliage
    mode: VLR
    #dataroot_HR: '../Vid4/foliage/HR'
    dataroot_LR: '../Vid4/foliage/LR'
    num_frames: 3 # the number of frames the network was trained to use to estimate the central frame
    srcolors: true # to generate images with 3 channels
    denoise_LRbic: true
    y_only: false #true
    # tensor_shape: CTHW # TCHW (SOFVSR), CTHW (EVSRGAN)

path:
  root: 'D:/Code/GitHub/BasicSR'
  pretrain_model_G: '../experiments/pretrained_models/video_x4.pth'

network_G:
  # SOFVSR:
  which_model_G: sofvsr_net
  n_frames: 3 # number of frames the network will use to estimate the central frame (n-1)/2. Must coincide with "num_frames" in the dataset.
  channels: 320 # feature extraction layer with 320 kernels of size 3 Ã— 3
  img_ch: 3 # # of input image channels: 3 for RGB and 1 for grayscale
  # for SR network:
  SR_net: rrdb #sofvsr | rrdb | pan
  sr_nf: 64 # for rrdb or pan
  sr_nb: 23 # for rrdb or pan
  sr_gc: 32 # for rrdb
  # sr_unf: 24 # for pan
  sr_gaussian_noise: true # for rrdb
  sr_plus: false # for rrdb
  # sr_sa: true # for pan
  # sr_upinter_mode: nearest # for pan

  # 3DSR:
  # which_model_G: sr3d_net
  # nf: 64 # of discrim filters
  # in_nc: 3 # of input image channels: 3 for RGB and 1 for grayscale
  # out_nc: 3 # of output image channels: 3 for RGB and 1 for grayscale

  # EVSRGAN:
  # which_model_G: RRDB_net # RRDB_net (original ESRGAN arch)
  # norm_type: null
  # mode: CNA
  # nf: 64 # of discrim filters in the first conv layer
  # nb: 23
  # in_nc: 3 # of input image channels: 3 for RGB and 1 for grayscale
  # out_nc: 3 # of output image channels: 3 for RGB and 1 for grayscale
  # gc: 32
  # group: 1
  # convtype: Conv3D
  # net_act: leakyrelu # swish | leakyrelu
  # gaussian: true # true | false
  # plus: false # true | false
  # ##finalact: tanh # Test. Activation function to make outputs fit in [-1, 1] range. Default = None. Coordinate with znorm.

  # EDVR:
  # which_model_G: EDVR_net
  # in_nc: 3 # Number of input image channels: 3 for RGB and 1 for grayscale
  # out_nc: 3 # Number of output image channels: 3 for RGB and 1 for grayscale
  # nf: 64 # Number of features (M=64, L=128)
  # n_frames: 3 # number of frames the network will use to estimate the central frame (n-1)/2. Must coincide with "num_frames" in the dataset.
  # deformable_groups: 8 # Number of deformable offset groups in the deformable layers
  # n_extract_block: 5 # Number of extract blocks
  # n_reconstruct_block: 10 # Number of reconstruction blocks (M=10, L=40)
  # predeblur: false # Use pre-deblur 
  # tsa: true # Use Temporal Spatial Attention