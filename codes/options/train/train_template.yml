
# Reading and Operating this file
# ~ is basically Null/None/False e.t.c, you can either use ~ as the value, or comment out the line
# A commented-out line's value is typically it's default but is disabled due to it being commented out
# When a line starts with two #'s (comment line starting with #), then when un-commenting, it's intended to be disabled
# for example, under network_G everything but ESRGAN's values are commented-out, so to show which should still be
# enabled/disabled, a double-comment is used

name: debug_001_template  # put "debug" in the name to enable debug mode, only enable to test code works!!!
use_tb_logger: true
model: srragan  # srragan | sr | srgan | ppon | asrragan
scale: 4
gpu_ids:
- 0

datasets:
  train:
    name: DIV2K
    mode: LRHROTF
    # high resolution / ground truth images
    dataroot_HR:
    - ../datasets/train/hr1
    - ../datasets/train/hr2
    - ../datasets/train/hr3
    # low resolution images. If there are missing LR images, they will be generated on the fly from HR
    dataroot_LR:
    - ../datasets/train/lr1
    - ../datasets/train/lr2
    - ../datasets/train/lr3
    subset_file: ~
    use_shuffle: true
    znorm: false  # true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.
    n_workers: 4  # 0 to disable CPU multithreading, or an integrer representing CPU threads to use for dataloading
    batch_size: 8
    HR_size: 128  #patch size. Default: 128. Needs to be coordinated with the patch size of the features network
    # Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
    #color: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
    #color_LR: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
    #color_HR: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
    # LR and HR modifiers. Random flip LR and HR or ignore provided LRs and generate new ones on the fly with defined probability:
    #rand_flip_LR_HR: false  # flip LR and HR during training.
    #flip_chance: 0.05  # Example: 0.05 = 5% chance of LR and HR flipping during training.
    #aug_downscale: 0.2  # Example: 0.6 = 60% chance of generating LR on the fly, even if LR dataset exists

    # If manually configuring on the fly generation of LR: (else, it will automatically default to Matlab-like downscale algorithm (777) when/if required
    lr_downscale: true
    lr_downscale_types:
    # select from [0,1,2,3,4,5,777] where each number is: (scale algorithm)
    # - cv2.INTER_NEAREST
    # - cv2.INTER_LINEAR
    # - cv2.INTER_CUBIC
    # - cv2.INTER_AREA
    # - cv2.INTER_LANCZOS4
    # - cv2.INTER_LINEAR_EXACT
    # - matlab.bicubic
    - 1
    - 2
    - 777

    # Rotations augmentations:
    use_flip: true  # flip lr with hr and hr with lr
    use_rot: true  # rotate images in 90 degree angles,
    hr_rrot: false  # rotate images in random degrees between -45 and 45

    # Noise and blur augmentations:
    lr_blur: false
    lr_blur_types:
    # select from: average | box | gaussian | bilateral | clean, `median` and `motion` aren't working yet
    - gaussian
    - clean
    - clean
    - clean
    lr_noise: false
    lr_noise_types:
    # select from: gaussian | JPEG | quantize | poisson | dither | s&p | speckle | clean
    - gaussian
    - clean
    - clean
    - clean
    - clean
    lr_noise2: false
    lr_noise_types2:
    # select from: gaussian | JPEG | quantize | poisson | dither | s&p | speckle | clean
    - dither
    - dither
    - clean
    - clean
    hr_noise: false
    hr_noise_types:
    # select from: gaussian | JPEG | quantize | poisson | dither | s&p | speckle | clean
    - gaussian
    - clean
    - clean
    - clean
    - clean

    # Color augmentations
    #lr_fringes: true
    #lr_fringes_chance: 0.4
    #auto_levels: HR  # "HR" | "LR" | "Both" //add auto levels to the images to expand dynamic range. Can use with SPL loss or (MS)-SSIM.
    #rand_auto_levels: 0.7  # Example: 0.4 = 40% chance of adding auto levels to images on the fly
    #unsharp_mask: true  # add a un-sharpening mask to HR images. Can work well together with the HFEN loss function.
    #rand_unsharp: 1  # Example: 0.5 = 50% chance of adding un-sharpening mask to HR images on the fly

    # Augmentations for classification or (maybe) in-painting networks:
    #lr_cutout: false
    #lr_erasing: false
  val:
    name: val_set14_part
    mode: LRHROTF
    dataroot_HR:
    - ../datasets/val/hr
    dataroot_LR:
    - ../datasets/val/lr
    znorm: false  # true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.

    # Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
    #color: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
    #color_LR: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
    #color_HR: y  # remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB

    #hr_crop: false
    lr_downscale: false
    lr_downscale_types:
    # select from [0,1,2,3,4,5] where each number is: (scale algorithm)
    # - cv2.INTER_NEAREST
    # - cv2.INTER_LINEAR
    # - cv2.INTER_CUBIC
    # - cv2.INTER_AREA
    # - cv2.INTER_LANCZOS4
    # - cv2.INTER_LINEAR_EXACT
    - 0
    - 1
path:
  root: D:/Code/GitHub/BasicSR
  pretrain_model_G: ../experiments/pretrained_models/RRDB_PSNR_x4.pth
  #resume_state: ../experiments/debug_002_RRDB_ESRGAN_x4_DIV2K/training_state/16.state

# Generator options:
network_G:
  # ESRGAN:
  which_model_G: RRDB_net  # RRDB_net | sr_resnet
  norm_type: ~
  mode: CNA
  nf: 64  # number of discriminator filters in the first convolution layer
  nb: 23
  in_nc: 3  # of input image channels: 3 for RGB and 1 for grayscale
  out_nc: 3  # of output image channels: 3 for RGB and 1 for grayscale
  gc: 32
  group: 1
  convtype: Conv2D  # convolution, Conv2D | PartialConv2D
  net_act: leakyrelu  # network activation, swish | leakyrelu
  #finalact: tanh  # in testing, activation function to make outputs fit in [-1,1] range. Coordinate with znorm

  # ASRGAN:
  #which_model_G: asr_resnet  # asr_resnet | asr_cnn
  #nf: 64

  # PPON:
  #which_model_G: ppon
  ##norm_type: ~
  #mode: CNA
  #nf: 64
  #nb: 24
  #in_nc: 3
  #out_nc: 3
  ##gc: 32
  #group: 1
  ##convtype: Conv2D  # Conv2D | PartialConv2D

  # SRGAN:
  #which_model_G: sr_resnet  # RRDB_net | sr_resnet
  #norm_type: ~
  #mode: CNA
  #nf: 64
  #nb: 16
  #in_nc: 3
  #out_nc: 3

  # SR:
  #which_model_G: RRDB_net  # RRDB_net | sr_resnet
  #norm_type: ~
  #mode: CNA
  #nf: 64
  #nb: 23
  #in_nc: 3
  #out_nc: 3
  #gc: 32
  #group: 1

# Discriminator options:
network_D:
  # ESRGAN (default) | PPON
  which_model_D: discriminator_vgg_128  # discriminator_vgg_128 | discriminator_vgg
  norm_type: batch
  act_type: leakyrelu
  mode: CNA  # CNA | NAC
  nf: 64
  in_nc: 3

  # ASRGAN (feature extraction)
  #which_model_D: discriminator_vgg_128_fea
  #norm_type: batch
  #act_type: leakyrelu
  #mode: CNA  # CNA | NAC
  #nf: 64
  #in_nc: 3
  #spectral_norm: true
  #self_attention: true
  #max_pool: true
  #poolsize: 4

# Schedulers options:
train:
  lr_G: !!float 1e-4  # starting lr_g
  weight_decay_G: 0
  beta1_G: 0.9
  lr_D: !!float 1e-4  # starting lr_d
  weight_decay_D: 0
  beta1_D: 0.9

  # For MultiStepLR (ESRGAN, default):,
  lr_scheme: MultiStepLR
  lr_steps:
  - 50000
  - 100000
  - 200000
  - 300000
  lr_gamma: 0.5  # lr change at every step (multiplied by)

  # For StepLR_Restart (PPON):
  # lr_gamma: 0.9  # lr change at every step (multiplied by)
  # lr_scheme: StepLR_Restart  # MultiStepLR | MultiStepLR_Restart | StepLR | StepLR_Restart | CosineAnnealingLR_Restart
  # lr_step_sizes:  # Steps for each restart for "StepLR_Restart"
  # - 200
  # - 100
  # - 250
  # restarts:  # Restart iterations for MultiStepLR_Restart | StepLR_Restart | CosineAnnealingLR_Restart
  # - 138000
  # - 172500
  # restart_weights: # lr_() * each weight in "restart_weights" for each restart in "restarts"
  # - 1
  # - 0.5
  # - 0.5
  ## clear_state: true

  # For MultiStepLR_Restart:
  # lr_gamma: 0.9
  # lr_scheme: MultiStepLR_Restart  # MultiStepLR | MultiStepLR_Restart | StepLR | StepLR_Restart | CosineAnnealingLR_Restart
  # lr_steps:  # For "MultiStepLR" and "MultiStepLR_Restart"
  # - 34500
  # - 69000
  # - 103500
  # - 155250
  # - 189750
  # - 241500
  # restarts:  # Restart iterations for MultiStepLR_Restart | StepLR_Restart | CosineAnnealingLR_Restart
  # - 138000
  # - 172500
  # restart_weights:  # lr_() * each weight in "restart_weights" for each restart in "restarts"
  # - 0.5
  # - 0.5
  ## clear_state: true

  # Losses:
  pixel_criterion: l1  # pixel loss, l1 | l2 | cb | elastic | relativel1 | l1cosinesim
  pixel_weight: !!float 1e-2  # 1e-2 | 1
  feature_criterion: l1  # feature loss (VGG feature network), l1 | l2 | cb | elastic
  feature_weight: 1
  #dis_feature_criterion: l1  # discriminator feature loss, asrragan only, l1 | l2 | cb | elastic
  #dis_feature_weight: 1
  #hfen_criterion: l1  # helps in deblurring and finding edges/lines, l1 | l2 | rel_l1 | rel_l2
  #hfen_weight: !!float 1e-1
  #tv_type: normal  # helps in denoising, reducing upscale artefacts
  #tv_weight: !!float 1e-6
  #tv_norm: 1  # 1 == l1 or 2 == l2. Change "tv_weight" so the l_g_tv is around 1e-02
  #ssim_type: ms-ssim  # ssim | ms-ssim  # helps to maintain luminance, contrast and covariance between SR and HR
  #ssim_weight: 1
  gan_type: vanilla  # vanilla | basic
  gan_weight: !!float 5e-3
  #lpips_weight: 1  # perceptual loss
  #lpips_type: net-lin  # net-lin | net
  #lpips_net: squeeze  # vgg | alex | squeeze
  #spl_weight: !!float 1e-3  # SPL loss function. note: needs to add a cap in the generator (finalcap) or it becomes unstable
  #spl_type: spl  # spl | gpl | cpl

  # for wgan-gp:
  #D_update_ratio: 1
  #D_init_iters: 0
  #gp_weigth: 10

  # For PPON:
  #train_phase: 1  # Training starting phase, can skip the first phases
  #phase1_s: 100  # -1 to skip. Need to coordinate with the LR steps. //COBranch: lr =  2e−4, decreased by the factor of 2 for every 1000 epochs (1.38e+5 iterations) 138k
  #phase2_s: 200  # -1 to skip. Need to coordinate with the LR steps. //SOBranch: λ = 1e+3 (?), lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
  #phase3_s: 5000000 # -1 to skip. Need to coordinate with the LR steps. //POBranch: η = 5e−3,  lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
  #phase4_s: 100100

  # Other training options:
  #finalcap: tanh  # Test. Cap Generator outputs to fit in: [-1,1] range ("tanh"), rescale tanh to [0,1] range ("scaltanh"), cap ("sigmoid") or clamp ("clamp") to [0,1] range. Default = None. Coordinate with znorm.
  #manual_seed: 0,  # only set if you want reproducibility as it will incur a performance cut, 0 to 2^32-1
  niter: !!float 5e5
  val_freq: !!float 5e3
logger:
  print_freq: 200,
  save_checkpoint_freq: !!float 5e3