{
  "name": "debug_001_template" //use “debug” in the name to run a test session and check everything is working. Does validation and state saving every 8 iterations.
  //"name": "001_template" //remove “debug” to run the real training session.
  , "use_tb_logger": true
  , "model":"srragan" //srragan | sr | srgan | ppon | asrragan
  , "scale": 4
  , "gpu_ids": [0]

  //Dataset options:
  , "datasets": {
    "train": {
      "name": "DIV2K"
      , "mode": "LRHROTF"
      //, "dataroot_HR": "../datasets/train/hr" //Original, with a single directory
      //, "dataroot_LR": "../datasets/train/lr" //Original, with a single directory
      , "dataroot_HR": [
            "../datasets/train/hr1",
            "../datasets/train/hr2",
            "../datasets/train/hr3"
            ] //high resolution / ground truth images
      , "dataroot_LR": [
            "../datasets/train/lr1",
            "../datasets/train/lr2"
            //"../datasets/train/lr3"
            ] //low resolution images. If there are missing LR images, they will be generated on the fly from HR
      , "subset_file": null
      , "use_shuffle": true
      , "znorm": false // true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.
      , "n_workers": 4 //0 to disable CPU multithreading, or an integrer representing CPU threads to use for dataloading
      , "batch_size": 8
      , "HR_size": 128 //patch size. Default: 128. Needs to be coordinated with the patch size of the features network
      
      // Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
      //, "color": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_LR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_HR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      
      // LR and HR modifiers. Random flip LR and HR or ignore provided LRs and generate new ones on the fly with defined probability:
      //, "rand_flip_LR_HR": false //true //flip LR and HR during training. 
      //, "flip_chance": 0.05 // Example: 0.05 = 5% chance of LR and HR flipping during training.
      //, "aug_downscale": 0.2 // Example: 0.6 = 60% chance of generating LR on the fly, even if LR dataset exists
      
      // If manually configuring on the fly generation of LR: (else, it will automatically default to Matlab-like downscale algorithm (777) when/if required
      , "lr_downscale": true //false
      , "lr_downscale_types": [1,2,777] //select from [0,1,2,3,4,5,777] where each number is: ["cv2.INTER_NEAREST", "cv2.INTER_LINEAR", "cv2.INTER_CUBIC", "cv2.INTER_AREA", "cv2.INTER_LANCZOS4", "cv2.INTER_LINEAR_EXACT", matlab.bicubic] //scale_algos //scaling interpolation options
      
      // Rotations augmentations:
      , "use_flip": true //flip images 
      , "use_rot": true //rotate images in 90 degree angles
      , "hr_rrot": false  //rotate images in random degress between -45 and 45
      
      // Noise and blur augmentations:
      , "lr_blur": false //true | false
      , "lr_blur_types":  ["gaussian", "clean", "clean", "clean"] //select from: ["average","box","gaussian","bilateral","clean"] //#blur options #median and motion aren't working yet
      , "lr_noise": false //true | false
      , "lr_noise_types": ["gaussian", "clean", "clean", "clean", "clean"] //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"]
      , "lr_noise2": false //true | false
      , "lr_noise_types2": ["dither", "dither", "clean", "clean"] //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"]
      , "hr_noise": false //true | false
      , "hr_noise_types": ["gaussian", "clean", "clean", "clean", "clean"] //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"]
      
      // Color augmentations
      //, "lr_fringes": true //true | false
      //, "lr_fringes_chance": 0.4
      //, "auto_levels": "HR" // "HR" | "LR" | "Both" // Can use with SPL loss or (MS)-SSIM
      //, "rand_auto_levels": 0.7 //0.4
      
      // Augmentations for classification or (maybe) inpainting networks:
      //, "lr_cutout": false
      //, "lr_erasing": false
    }
    , "val": {
      "name": "val_set14_part"
      , "mode": "LRHROTF"
      , "dataroot_HR": "../datasets/val/hr"
      , "dataroot_LR": "../datasets/val/lr"
      
      , "znorm": false // true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.
      
      // Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
      //, "color": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_LR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_HR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      
      //, "hr_crop": false //disabled
      , "lr_downscale": false
      , "lr_downscale_types": [0,1] //[0,1,2,3,4,5] //["cv2.INTER_NEAREST", "cv2.INTER_LINEAR", "cv2.INTER_CUBIC", "cv2.INTER_AREA", "cv2.INTER_LANCZOS4", "cv2.INTER_LINEAR_EXACT"] //scale_algos //scaling interpolation options
    }
  }

  , "path": {
    "root": "D:/Code/GitHub/BasicSR"
    , "pretrain_model_G": "../experiments/pretrained_models/RRDB_PSNR_x4.pth"
    //, "pretrain_model_G": "../experiments/pretrained_models/RRDB_ESRGAN_x4.pth"
    //, "pretrain_model_G": "../experiments/pretrained_models/PPON_G.pth"
    // , "resume_state": "../experiments/debug_002_RRDB_ESRGAN_x4_DIV2K/training_state/16.state"
  }

  //Generator options:
  , "network_G": {
    //ESRGAN:
    "which_model_G": "RRDB_net" // RRDB_net | sr_resnet
    , "norm_type": null
    , "mode": "CNA"
    , "nf": 64 //# of discrim filters in the first conv layer
    , "nb": 23
    , "in_nc": 3 //# of input image channels: 3 for RGB and 1 for grayscale
    , "out_nc": 3 //# of output image channels: 3 for RGB and 1 for grayscale
    , "gc": 32
    , "group": 1
    , "convtype": "Conv2D" //"Conv2D" | "PartialConv2D"
    , "net_act": "leakyrelu" //"swish" | "leakyrelu"
    ////, "finalact": "tanh" // Test. Activation function to make outputs fit in [-1, 1] range. Default = None. Coordinate with znorm.
    
    //ASRGAN:
    //"which_model_G": "asr_resnet" // "asr_resnet" | "asr_cnn"
    //, "nf": 64
    
    //PPON:
    //"which_model_G": "ppon" // | ppon
    ////, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 24
    //, "in_nc": 3
    //, "out_nc": 3
    ////, "gc": 32
    //, "group": 1
    ////, "convtype": "Conv2D" //"Conv2D" | "PartialConv2D"
    
    //SRGAN:
    //"which_model_G": "sr_resnet" // RRDB_net | sr_resnet
    //, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 16
    //, "in_nc": 3
    //, "out_nc": 3
    
    //SR:
    //"which_model_G": "RRDB_net" // RRDB_net | sr_resnet
    //, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 23
    //, "in_nc": 3
    //, "out_nc": 3
    //, "gc": 32
    //, "group": 1
  }

  //Discriminator options:
  , "network_D": {
    //ESRGAN (default)| PPON:
    "which_model_D": "discriminator_vgg_128" // discriminator_vgg_128 | discriminator_vgg
    , "norm_type": "batch"
    , "act_type": "leakyrelu"
    , "mode": "CNA" // "CNA" | "NAC"
    , "nf": 64
    , "in_nc": 3
    
    //ASRGAN (feature extraction):
    //"which_model_D": "discriminator_vgg_128_fea" // discriminator_vgg_128_fea
    //, "norm_type": "batch"
    //, "act_type": "leakyrelu"
    //, "mode": "CNA" // "CNA" | "NAC"
    //, "nf": 64
    //, "in_nc": 3
    //, "spectral_norm": true
    //, "self_attention": true
    //, "max_pool": true
    //, "poolsize": 4
  }

  //Schedulers options:
  , "train": {
    "lr_G": 1e-4 //2e-4 //starting lr_g //Test, default: 1e-4
    , "weight_decay_G": 0
    , "beta1_G": 0.9
    , "lr_D": 1e-4 //4e-4 //starting lr_d //Test, default: 1e-4
    , "weight_decay_D": 0
    , "beta1_D": 0.9
    
    //For MultiStepLR (ESRGAN, default):
    , "lr_scheme": "MultiStepLR"
    , "lr_steps": [50000, 100000, 200000, 300000] //training from scratch
    //, "lr_steps": [50000, 75000, 85000, 100000] //finetuning
    , "lr_gamma": 0.5 //lr change at every step (multiplied by)
    
    //For StepLR_Restart (PPON):
    //, "lr_gamma": 0.9 //lr change at every step (multiplied by)
    ///, "lr_scheme": "StepLR_Restart" // "MultiStepLR" | MultiStepLR_Restart | "StepLR" | "StepLR_Restart" | CosineAnnealingLR_Restart
    //, "lr_step_sizes": [200, 100, 250] //Steps for each restart for "StepLR_Restart"
    //, "restarts": [138000, 172500] //Restart iterations for "MultiStepLR_Restart", "StepLR_Restart" and "CosineAnnealingLR_Restart"
    //, "restart_weights": [1, 0.5, 0.5]//lr_() * each weight in "restart_weights" for each restart in "restarts"    
    ////, "clear_state": true
    
    //For MultiStepLR_Restart:
    //, "lr_gamma": 0.9
    //, "lr_scheme": "MultiStepLR_Restart" // "MultiStepLR" | MultiStepLR_Restart | "StepLR" | "StepLR_Restart" | CosineAnnealingLR_Restart
    //, "lr_steps": [34500, 69000, 103500, 155250, 189750, 241500] //For "MultiStepLR" and "MultiStepLR_Restart"
    //, "restarts": [138000, 172500] //Restart iterations for "MultiStepLR_Restart", "StepLR_Restart" and "CosineAnnealingLR_Restart"
    //, "restart_weights": [0.5, 0.5] //lr_() * each weight in "restart_weights" for each restart in "restarts"
    ////, "clear_state": true
    
    // Losses:
    , "pixel_criterion": "l1" //"l1" | "l2" | "cb" | "elastic" | "relativel1" | "l1cosinesim" //pixel loss
    , "pixel_weight": 1e-2 // 1e-2 | 1
    , "feature_criterion": "l1" //"l1" | "l2" | "cb" | "elastic" //feature loss (VGG feature network)
    , "feature_weight": 1
    //, "dis_feature_criterion": "l1" //"l1" | "l2" | "cb" | "elastic" //discriminator feature loss (only for asrragan)
    //, "dis_feature_weight": 1 //(only for asrragan)
    //, "hfen_criterion": "l1" //hfen: "l1" | "l2" | "rel_l1" | "rel_l2" //helps in deblurring and finding edges, lines
    //, "hfen_weight": 1e-1
    //, "tv_type": "normal" //helps in denoising, reducing upscale artefacts
    //, "tv_weight": 1e-6
    //, "tv_norm": 2 // 1 for l1 (default) or 2 for l2. Change "tv_weight" so the l_g_tv is around 1e-02
    //, "ssim_type": "ms-ssim" //"ssim" | "ms-ssim" //helps to maintain luminance, contrast and covariance between SR and HR
	//, "ssim_weight": 1
    , "gan_type": "vanilla" //"vanilla" | basic 
    , "gan_weight": 5e-3 //*
    //, "lpips_weight": 1 //perceptual loss
    //, "lpips_type": "net-lin" // net-lin | net *
    //, "lpips_net": "squeeze" // "vgg" | "alex" | "squeeze" 
    //, "spl_weight": 1e-3 //SPL loss function. note: needs to add a cap in the generator (finalcap) or it becomes unstable
    //, "spl_type": "spl" //"spl" | "gpl" | "cpl" //
	
    //for wgan-gp
    // , "D_update_ratio": 1
    // , "D_init_iters": 0
    // , "gp_weigth": 10
    
    // For PPON:
    //, "train_phase": 1 //Training starting phase, can skip the first phases
    //, "phase1_s": 100 //5000 //100 //5000 //138000 //-1 to skip. Need to coordinate with the LR steps. //COBranch: lr =  2e−4, decreased by the factor of 2 for every 1000 epochs (1.38e+5 iterations) 138k
    //, "phase2_s": 200 //10000 //200 //10000 //172500 //-1 to skip. Need to coordinate with the LR steps. //SOBranch: λ = 1e+3 (?), lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
    //, "phase3_s": 5000000 //207000 //-1 to skip. Need to coordinate with the LR steps. //POBranch: η = 5e−3,  lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
    //, "phase4_s": 100100

  //Other training options:
    //, "finalcap": "tanh" // Test. Cap Generator outputs to fit in: [-1, 1] range ("tanh"), rescale tanh to [0,1] range ("scaltanh"), cap ("sigmoid") or clamp ("clamp") to [0,1] range. Default = None. Coordinate with znorm.
    , "manual_seed": 0
    , "niter": 5e5
    , "val_freq": 1000 //5e3
  }

  , "logger": {
    "print_freq": 200
    , "save_checkpoint_freq": 5e3
  }
}
