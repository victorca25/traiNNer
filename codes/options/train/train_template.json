{
  "name": "debug_001_template"
  //use "debug" in the name to run a test session and check everything is working. Does validation and state saving every 8 iterations.
  //"name": "001_template" //remove "debug" to run the real training session.,
  "use_tb_logger": true,
  "model": "srragan"
  //srragan | sr | srgan | ppon | asrragan,
  "scale": 4,
  "gpu_ids": [
    0
  ]

  //Dataset options:,
  "datasets": {
    "train": {
      "name": "DIV2K",
      "mode": "LRHROTF"
      //, "dataroot_HR": "../datasets/train/hr" //Original, with a single directory
      //, "dataroot_LR": "../datasets/train/lr" //Original, with a single directory,
      "dataroot_HR": [
        "../datasets/train/hr1",
        "../datasets/train/hr2",
        "../datasets/train/hr3"
      ]
      //high resolution / ground truth images,
      "dataroot_LR": [
        "../datasets/train/lr1",
        "../datasets/train/lr2"
        //"../datasets/train/lr3"
      ]
      //low resolution images. If there are missing LR images, they will be generated on the fly from HR,
      "subset_file": null,
      "use_shuffle": true,
      "znorm": false
      // true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.,
      "n_workers": 4
      //0 to disable CPU multithreading, or an integrer representing CPU threads to use for dataloading,
      "batch_size": 8,
      "HR_size": 128
      //patch size. Default: 128. Needs to be coordinated with the patch size of the features network

      // Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
      //, "color": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_LR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_HR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB

      // LR and HR modifiers. Random flip LR and HR or ignore provided LRs and generate new ones on the fly with defined probability:
      //, "rand_flip_LR_HR": false //true //flip LR and HR during training. 
      //, "flip_chance": 0.05 // Example: 0.05 = 5% chance of LR and HR flipping during training.
      //, "aug_downscale": 0.2 // Example: 0.6 = 60% chance of generating LR on the fly, even if LR dataset exists

      // If manually configuring on the fly generation of LR: (else, it will automatically default to Matlab-like downscale algorithm (777) when/if required,
      "lr_downscale": true
      //false,
      "lr_downscale_types": [
        1,
        2,
        777
      ]
      //select from [0,1,2,3,4,5,777] where each number is: ["cv2.INTER_NEAREST", "cv2.INTER_LINEAR", "cv2.INTER_CUBIC", "cv2.INTER_AREA", "cv2.INTER_LANCZOS4", "cv2.INTER_LINEAR_EXACT", matlab.bicubic] //scale_algos //scaling interpolation options

      // Rotations augmentations:,
      "use_flip": true
      //flip images ,
      "use_rot": true
      //rotate images in 90 degree angles,
      "hr_rrot": false
      //rotate images in random degress between -45 and 45

      // Noise and blur augmentations:,
      "lr_blur": false
      //true | false,
      "lr_blur_types": [
        "gaussian",
        "clean",
        "clean",
        "clean"
      ]
      //select from: ["average","box","gaussian","bilateral","clean"] //#blur options #median and motion aren't working yet,
      "lr_noise": false
      //true | false,
      "lr_noise_types": [
        "gaussian",
        "clean",
        "clean",
        "clean",
        "clean"
      ]
      //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"],
      "lr_noise2": false
      //true | false,
      "lr_noise_types2": [
        "dither",
        "dither",
        "clean",
        "clean"
      ]
      //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"],
      "hr_noise": false
      //true | false,
      "hr_noise_types": [
        "gaussian",
        "clean",
        "clean",
        "clean",
        "clean"
      ]
      //select from: ["gaussian", "JPEG", "quantize", "poisson", "dither", "s&p", "speckle", "clean"]

      // Color augmentations
      //, "lr_fringes": true //true | false
      //, "lr_fringes_chance": 0.4
      //, "auto_levels": "HR" // "HR" | "LR" | "Both" //add auto levels to the images to expand dynamic range. Can use with SPL loss or (MS)-SSIM.
      //, "rand_auto_levels": 0.7 //Example: 0.4 = 40% chance of adding auto levels to images on the fly
      //, "unsharp_mask": true //add a unsharpening mask to HR images. Can work well together with the HFEN loss function.
      //, "rand_unsharp": 1 //Example: 0.5 = 50% chance of adding unsharpening mask to HR images on the fly

      // Augmentations for classification or (maybe) inpainting networks:
      //, "lr_cutout": false
      //, "lr_erasing": false
    },
    "val": {
      "name": "val_set14_part",
      "mode": "LRHROTF",
      "dataroot_HR": "../datasets/val/hr",
      "dataroot_LR": "../datasets/val/lr",
      "znorm": false
      // true | false // To normalize images in [-1, 1] range. Default = None (range [0,1]). Can use with activation function like tanh.

      // Color space conversion: "color" for both LR and HR, "color_LR" for LR independently, "color_HR" for HR independently
      //, "color": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_LR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB
      //, "color_HR": "y" //remove for no conversion (RGB) | "y" for Y in YCbCr | "gray" to convert RGB to grayscale | "RGB" to convert gray to RGB

      //, "hr_crop": false //disabled,
      "lr_downscale": false,
      "lr_downscale_types": [
        0,
        1
      ]
      //[0,1,2,3,4,5] //["cv2.INTER_NEAREST", "cv2.INTER_LINEAR", "cv2.INTER_CUBIC", "cv2.INTER_AREA", "cv2.INTER_LANCZOS4", "cv2.INTER_LINEAR_EXACT"] //scale_algos //scaling interpolation options
    }
  },
  "path": {
    "root": "D:/Code/GitHub/BasicSR",
    "pretrain_model_G": "../experiments/pretrained_models/RRDB_PSNR_x4.pth"
    //, "pretrain_model_G": "../experiments/pretrained_models/RRDB_ESRGAN_x4.pth"
    //, "pretrain_model_G": "../experiments/pretrained_models/PPON_G.pth"
    // , "resume_state": "../experiments/debug_002_RRDB_ESRGAN_x4_DIV2K/training_state/16.state"
  }

  //Generator options:,
  "network_G": {
    //ESRGAN:
    "which_model_G": "RRDB_net"
    // RRDB_net | sr_resnet,
    "norm_type": null,
    "mode": "CNA",
    "nf": 64
    //# of discrim filters in the first conv layer,
    "nb": 23,
    "in_nc": 3
    //# of input image channels: 3 for RGB and 1 for grayscale,
    "out_nc": 3
    //# of output image channels: 3 for RGB and 1 for grayscale,
    "gc": 32,
    "group": 1,
    "convtype": "Conv2D"
    //"Conv2D" | "PartialConv2D",
    "net_act": "leakyrelu"
    //"swish" | "leakyrelu"
    ////, "finalact": "tanh" // Test. Activation function to make outputs fit in [-1, 1] range. Default = None. Coordinate with znorm.

    //ASRGAN:
    //"which_model_G": "asr_resnet" // "asr_resnet" | "asr_cnn"
    //, "nf": 64

    //PPON:
    //"which_model_G": "ppon" // | ppon
    ////, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 24
    //, "in_nc": 3
    //, "out_nc": 3
    ////, "gc": 32
    //, "group": 1
    ////, "convtype": "Conv2D" //"Conv2D" | "PartialConv2D"

    //SRGAN:
    //"which_model_G": "sr_resnet" // RRDB_net | sr_resnet
    //, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 16
    //, "in_nc": 3
    //, "out_nc": 3

    //SR:
    //"which_model_G": "RRDB_net" // RRDB_net | sr_resnet
    //, "norm_type": null
    //, "mode": "CNA"
    //, "nf": 64
    //, "nb": 23
    //, "in_nc": 3
    //, "out_nc": 3
    //, "gc": 32
    //, "group": 1
  }

  //Discriminator options:,
  "network_D": {
    //ESRGAN (default)| PPON:
    "which_model_D": "discriminator_vgg_128"
    // discriminator_vgg_128 | discriminator_vgg,
    "norm_type": "batch",
    "act_type": "leakyrelu",
    "mode": "CNA"
    // "CNA" | "NAC",
    "nf": 64,
    "in_nc": 3

    //ASRGAN (feature extraction):
    //"which_model_D": "discriminator_vgg_128_fea" // discriminator_vgg_128_fea
    //, "norm_type": "batch"
    //, "act_type": "leakyrelu"
    //, "mode": "CNA" // "CNA" | "NAC"
    //, "nf": 64
    //, "in_nc": 3
    //, "spectral_norm": true
    //, "self_attention": true
    //, "max_pool": true
    //, "poolsize": 4
  }

  //Schedulers options:,
  "train": {
    "lr_G": 1e-4
    //2e-4 //starting lr_g //Test, default: 1e-4,
    "weight_decay_G": 0,
    "beta1_G": 0.9,
    "lr_D": 1e-4
    //4e-4 //starting lr_d //Test, default: 1e-4,
    "weight_decay_D": 0,
    "beta1_D": 0.9

    //For MultiStepLR (ESRGAN, default):,
    "lr_scheme": "MultiStepLR",
    "lr_steps": [
      50000,
      100000,
      200000,
      300000
    ]
    //training from scratch
    //, "lr_steps": [50000, 75000, 85000, 100000] //finetuning,
    "lr_gamma": 0.5
    //lr change at every step (multiplied by)

    //For StepLR_Restart (PPON):
    //, "lr_gamma": 0.9 //lr change at every step (multiplied by)
    ///, "lr_scheme": "StepLR_Restart" // "MultiStepLR" | MultiStepLR_Restart | "StepLR" | "StepLR_Restart" | CosineAnnealingLR_Restart
    //, "lr_step_sizes": [200, 100, 250] //Steps for each restart for "StepLR_Restart"
    //, "restarts": [138000, 172500] //Restart iterations for "MultiStepLR_Restart", "StepLR_Restart" and "CosineAnnealingLR_Restart"
    //, "restart_weights": [1, 0.5, 0.5]//lr_() * each weight in "restart_weights" for each restart in "restarts"    
    ////, "clear_state": true

    //For MultiStepLR_Restart:
    //, "lr_gamma": 0.9
    //, "lr_scheme": "MultiStepLR_Restart" // "MultiStepLR" | MultiStepLR_Restart | "StepLR" | "StepLR_Restart" | CosineAnnealingLR_Restart
    //, "lr_steps": [34500, 69000, 103500, 155250, 189750, 241500] //For "MultiStepLR" and "MultiStepLR_Restart"
    //, "restarts": [138000, 172500] //Restart iterations for "MultiStepLR_Restart", "StepLR_Restart" and "CosineAnnealingLR_Restart"
    //, "restart_weights": [0.5, 0.5] //lr_() * each weight in "restart_weights" for each restart in "restarts"
    ////, "clear_state": true

    // Losses:,
    "pixel_criterion": "l1"
    //"l1" | "l2" | "cb" | "elastic" | "relativel1" | "l1cosinesim" //pixel loss,
    "pixel_weight": 1e-2
    // 1e-2 | 1,
    "feature_criterion": "l1"
    //"l1" | "l2" | "cb" | "elastic" //feature loss (VGG feature network),
    "feature_weight": 1
    //, "dis_feature_criterion": "l1" //"l1" | "l2" | "cb" | "elastic" //discriminator feature loss (only for asrragan)
    //, "dis_feature_weight": 1 //(only for asrragan)
    //, "hfen_criterion": "l1" //hfen: "l1" | "l2" | "rel_l1" | "rel_l2" //helps in deblurring and finding edges, lines
    //, "hfen_weight": 1e-1
    //, "tv_type": "normal" //helps in denoising, reducing upscale artefacts
    //, "tv_weight": 1e-6
    //, "tv_norm": 2 // 1 for l1 (default) or 2 for l2. Change "tv_weight" so the l_g_tv is around 1e-02
    //, "ssim_type": "ms-ssim" //"ssim" | "ms-ssim" //helps to maintain luminance, contrast and covariance between SR and HR
    //, "ssim_weight": 1,
    "gan_type": "vanilla"
    //"vanilla" | basic ,
    "gan_weight": 5e-3
    //*
    //, "lpips_weight": 1 //perceptual loss
    //, "lpips_type": "net-lin" // net-lin | net *
    //, "lpips_net": "squeeze" // "vgg" | "alex" | "squeeze" 
    //, "spl_weight": 1e-3 //SPL loss function. note: needs to add a cap in the generator (finalcap) or it becomes unstable
    //, "spl_type": "spl" //"spl" | "gpl" | "cpl" //

    //for wgan-gp
    // , "D_update_ratio": 1
    // , "D_init_iters": 0
    // , "gp_weigth": 10

    // For PPON:
    //, "train_phase": 1 //Training starting phase, can skip the first phases
    //, "phase1_s": 100 //5000 //100 //5000 //138000 //-1 to skip. Need to coordinate with the LR steps. //COBranch: lr =  2e−4, decreased by the factor of 2 for every 1000 epochs (1.38e+5 iterations) 138k
    //, "phase2_s": 200 //10000 //200 //10000 //172500 //-1 to skip. Need to coordinate with the LR steps. //SOBranch: λ = 1e+3 (?), lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
    //, "phase3_s": 5000000 //207000 //-1 to skip. Need to coordinate with the LR steps. //POBranch: η = 5e−3,  lr = 1e−4 and halved at every 250 epochs (3.45e+4iterations) 34.5k
    //, "phase4_s": 100100

    //Other training options:
    //, "finalcap": "tanh" // Test. Cap Generator outputs to fit in: [-1, 1] range ("tanh"), rescale tanh to [0,1] range ("scaltanh"), cap ("sigmoid") or clamp ("clamp") to [0,1] range. Default = None. Coordinate with znorm.,
    "manual_seed": 0,
    "niter": 5e5,
    "val_freq": 1000
    //5e3
  },
  "logger": {
    "print_freq": 200,
    "save_checkpoint_freq": 5e3
  }
}
